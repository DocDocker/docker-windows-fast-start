Docker & Windows. Быстрый старт.
Дисклеймер
Текст не претендует на полноту и точность. Все термины и концепции описаны кратко своими словами, чтобы не перегружаться на старте и затратить минимальное время для достижения результата.
Все, что выходит за рамки темы "запуск и работа с docker на hyper-v", рассматривается вскользь, поскольку для остальных случаев есть огромное количество весьма хорошей документации.
Для подготовки использовались windows 10 pro, windows 8.1 pro, windows 2008 r2, windows 2012 r2 std, virtualbox и hyper-v. На других версиях не проверялось, но причин для проблем не видится, хотя и может привести к увеличению затраченного на освоение времени. 
Буду признателен за информацию о результатах практической проверки.

Предисловие
“Счастье для всех, даром, и пусть никто не уйдет обиженным!”
А. и Б. Стругацкие
Допустим, что Вам понадобилось развернуть свой git-сервер, postgresql, apache, elasticsearch, zabbix... остановимся на postgresql и git-сервере. При этом со временем туго, нет черного пояса по linux, есть минимальный опыт использования virtualbox, hyper-v или другой системы виртуализации, а также опыт накликивания мышкой новой базы в какой-нибудь СУБД.

Какие есть варианты?
Поставить и настроить postgres и gogs вручную. Этот вариант требует от нескольких часов до нескольких дней на изучение процесса настройки и поднятие postgres и gogs.
Сделать это с помощью vagrant или docker. Эти варианты требуют от нескольких часов до нескольких дней на изучение технологии, плюс несколько минут на получение конечного результата.
Другие варианты, но мы их гневно отвергнем :)

Почему vagrant или docker кажутся предпочтительней? Потому что изучив однажды, их можно использовать для поднятия не только postgres и gogs, что в общем случае гораздо выгодней. У этих технологий масса достоинств, но здесь и сейчас наиболее важно то, что сообщество уже проделало колоссальную работу по автоматизации процесса установки и настройки огромного количества ПО, вложив свои знания и опыт. Проще говоря, можно в считанные минуты воспользоваться опытом профессионалов. Безвозмездно.

Почему docker? Просто потому, что статья про него, а не про что-нибудь другое. Лично для меня большую ценность имеет экономность докера в плане утилизации ресурсов.

В свое время мне не удалось найти хороший практический мануал, который ответил бы на мои вопросы и позволил за один присест дойти до конечного результата именно в windows и именно с hyper-v. В итоге получился еще один мануал среди сотен других. Который, возможно, именно Вам подойдет лучше других.
Другой, более важной причиной сесть за статью стало распространенное мнение, что начать использовать docker - дело непростое и не быстрое. Мне бы хотелось помочь тем, кто хочет начать, но не знает как.

Согласование определений:
Хост - наша машинка, на которой будет взлетать докер
Docker-хост - виртуальная машина, расположенная на хосте, на котором будет взлетать докер
Docker-machine - утилита для управления docker-хостами
В тексте синим фоном выделены инструкции, выполняемые в powershell, черным - в bash на docker-машине.
Цели
В целом понять, как работает docker под windows
Запустить docker под windows с hyper-v
Запустить postgresql и gogs, запустить второй экземпляр postgres с патчами 1С
Установить зависимости между контейнерами (настроить порядок запуска)
Разобраться с хранением данных, бэкапом и переносом на другой docker-хост
Уложиться в 1 час
Как это работает
“- А если эта хренотень пробьет обшивку?
- Исключено. Взрыв направлен внутрь кольца”
С. Лукьяненко
В начале своей трудовой деятельности в роли бубнотряса, докрутив очередную капризную программу до нужной кондиции, я иногда думал: вот бы теперь все это завернуть в этакий контейнер, а потом вжух - и оно где хочешь работает! С практической точки зрения docker - это оно и есть. Другими словами, docker - инструмент для виртуализации приложений.
Основное отличие от классической виртуализации в том, что виртуализируется не вся ОС целиком, что довольно накладно для запуска одного приложения, а только необходимая часть окружения. В общем случае это ядро, файловая система, сеть и зависимости. В итоге имеем минимальные, по сравнению с виртуалками, накладные расходы, а также потрясающую скорость развертывания и запуска.

Контейнеры создаются из образов. Образ - это файл, содержащий приложение вместе с “обвязкой”. В процессе создания образа можно делать “снимки” на разных этапах. Каждый снимок - это “слой” образа, информация об этих слоях хранится в самом образе. В настоящее время огромное количество образов уже создано сообществом, они доступны на докер-хабах (главный хаб - https://hub.docker.com). Ну и, конечно же, можно сделать любой нужный образ самостоятельно (если сделаете образ - не забудьте им поделиться).
 
Какое ПО имеет смысл контейнеризировать? Наверное, любое, при условии, что есть выигрыш в удобстве/скорости развертывания в сравнении с другими способами. Или есть выигрыш в удобстве использования. И точно имеет смысл использовать docker для обеспечения требования однотипности окружения.

Под linux можно легко делать это как с сервисами типа веб-сервера или СУБД, так и с обычными приложениями - браузер или клиент 1С (осторожно - лицензирование!). Под windows оборачивать клиентское ПО в контейнер уже не так приятно, поскольку дополнительно потребуется настроить “проброс картинки” из докера. Да, я тоже пока не знаю зачем, но если очень захочется, то это возможно. 

Мой внутренний кэп говорит так: как и любой другой инструмент, docker следует применять, когда от него хорошо и приятно, и не следует применять, когда от него больно или трудно.
 
Для лучшего понимания можно почитать источники, приведенные в приложениях, но для достижения поставленных целей необязательно делать это прямо сейчас. Напомню, цель - познакомиться и запустить. Под windows.
Подготовка
Во всех примерах предполагается использование powershell - начиная с windows 7 он поставляется в составе ОС, для windows XP придется установить отсюда: https://support.microsoft.com/ru-ru/kb/968929.
Для упрощения процесса предполагается, что powershell всегда запущен с правами администратора.

Для начала нужно разрешить выполнение неподписанных сценариев:
Set-ExecutionPolicy -ExecutionPolicy Bypass
На вопрос, точно ли мы в своем уме, отвечаем ‘A’ (All), или Y (Yes), если варианта A нет (зависит от версии).

Потребуется chocolatey и boxstarter - ставим, если не установлены:
iwr https://chocolatey.org/install.ps1 | iex
choco install boxstarter -y
Перезапускаем консоль, поскольку boxstarter не озаботился обновить переменные окружения в текущей сессии.

Все инструкции приведены для hyper-v, но могут быть достаточно безболезненно транслированы для других систем заменой слова “hyperv” на  “virtualbox” или “vmware”.

Установка hyper-v для windows, начиная от 8 и 2008 r2:
cinst Microsoft-Hyper-V-All -source windowsFeatures  -y
Для остальных версий подойдет virtualbox или любой другой гипервизор.
Как это работает под windows
Плохая новость в том, что нельзя просто так взять и поднять докер - в основе докер-песочницы лежит ядро linux.
Чтобы облегчить страдания виндоводов (я в их числе) и отсрочить освоение linux, сам докер как сервис (сервер) размещается в виртуальной машине, а на хосте настраивается "обертка" командной строки (клиент), позволяющая делать все операции так, будто ложки виртуальной машины нет. Хорошая новость в том, что это делается в пару копипастов и не требует скафандра какой-либо подготовки.

Получается, что от “классической” виртуализации избавиться не удастся? Верно, в случае windows она необходима. Отсюда вытекают ограничения:
Забудьте про “реальное” железо. На практике это несущественно, так как основная цель - как раз получить портабельность и независимость от окружения. 
Докер-хост ограничен ресурсами виртуальной, а не реальной системы (ядра, память, диски, сеть). Не знаю, стоит ли рассматривать это как недостаток, так как hyper-v позволяет очень гибко управлять ресурсами, просто нужно иметь это ввиду. В некоторых случаях это можно расценивать и как фичу.
Повышенные накладные расходы на виртуализацию. Это так, но опять же все не так страшно: сама ОС с докер-хостом грузится в память и занимает около 50 мегабайт, что вполне можно пережить. И в любом случае это гораздо экономней “полноценной” виртуалки.

Итак, для работы docker под windows нужна виртуалка с docker и окружение для работы из привычной среды обитания. Рассмотрим три варианта это сделать. Первые два приведены для общей картины и рассматриваться далее не будут. Кроме того, они построены на третьем варианте.
Вариант 1: есть windows 10 и hyper-v
Все прекрасно, на этот случай есть Docker for Windows. Достаточно выполнить:
iwr https://download.docker.com/win/stable/InstallDocker.msi | iex
Что будет:
создана и запущена виртуалка с docker
установлена утилита docker для работы из консольки
Установлена служба, транслирующая все команды, выполняемые вами в cmd или posh, в виртуалку с докером
Установлена графическая оболочка kitematic для управления контейнерами
Диск C проброшен в виртуалку и смонтирован по адресу "/C" (другие диски можно пробросить с помощью kitematic)
В трее появится вот такой симпатичный кит:
 	
Вариант 2: есть windows любой (ну, почти) версии, virtualbox устраивает в качестве среды виртуализации
В целом все похоже на первый случай, так как есть docker toolbox. Установка:
iwr https://github.com/docker/toolbox/releases/download/v1.12.0/DockerToolbox-1.12.0.exe | iex
После установки нужно запустить из пуска ярлык "Docker Quickstart Terminal" и дождаться окончания процесса.
Вариант 3: универсальный
Этот вариант родился в результате изучения вопроса, как же заставить работать docker под hyper-v на windows server 2012. Это кажется странным, но внятного ответа на этот вопрос на официальном сайте докера нет.

Если посмотреть, что скрывается под капотом в первых двух случаях, то обнаружится, что есть гипервизор, виртуалка, утилита для создания виртуалки и управления ей, всяческая требуха, скрывающая некоторые моменты взаимодействия с докером, и все это завернуто в красивый инсталлятор. Так вот, если отбросить шелуху, то кроме гипервизора останутся виртуалка и утилита, а эти штуки вполне можно поставить без инсталлятора. Более того, это дает определенные бонусы по сравнению с docker for windows и docker toolbox:
Возможность создания более одного докер-хоста на одном хосте windows
Возможность управления удаленными докер-хостами
Приятное (хоть и обманчивое) чувство понимания происходящего

Итак, чтобы запустить докер, нам понадобится docker-machine. Это консольная утилита, позволяющая штамповать докер-хосты, управлять существующими докер-хостами, и выполнять команды, не ходя в linux.

Установка
Ставим docker-machine и docker, создаем docker-хост:
choco install docker-machine -y
choco install docker -y
docker-machine create --driver hyperv --hyperv-virtual-switch “local” default
local - название виртуального коммутатора hyper-v (предлагаю садить виртуалку на общую сеть, пока не появится собственная точка зрения), default - имя докер-машины (может быть любое, default позволяет в дальнейшем опускать имя в параметрах команд).
*Название виртуального коммутатора не должно содержать русских символов. Посмотреть имена коммутаторов и/или изменить имя уже существующего можно в Диспетчере Hyper-V:

 
Машина запущена и готова к работе.
Для удобства ползанья по файловой системе докер-машины можно завершить настройку установкой winscp (см. приложения)

Базовые операции
Для начала разберемся с основными операциями на примере portainer. Это такой простой и приятный gui-интерфейс для управления контейнерами. И запускать мы его будем, разумеется, в контейнере.
Для тренировки начнем в новой консоли (с повышенными правами).

Устанавливаем контекст свежеиспеченного докер-хоста:
docker-machine env default | iex
Получаем настройки окружения для машины default и выполняем как код.
	Теперь все команды docker будут выполняться на указанном docker-хосте.

Создаем и запускаем контейнер:
docker run -p 9001:9000 portainer/portainer
	Из хаба hub.docker.com будет скачан образ portainer/portainer,
из образа будет создан и запущен контейнер,
порт 9001 извне будет проброшен  на порт 9000 в контейнере
Так, процесс пошел, идет скачивание, запуск...
Контейнер, кажется, повис? Нет, он работает, просто “привязан” к консоли и ему нечего нам сказать. Это foreground-режим работы контейнера, в котором пользователь может взаимодействовать с приложением. Такой режим работы необходим, например, для firefox. Для того, чтобы отправлять контейнер сразу в фоновый режим, служит ключ -d. Поскольку portainer не собирается с нами общаться, нужно его “отцепить” - для этого достаточно нажать ctrl-c. Теперь portainer работает в фоне. Чтобы убедиться в этом, достаточно выполнить команду docker attach <ИмяКонтейнера>. Но мы же не знаем имя контейнера! А все потому, что не задали его при создании, и docker придумал имя сам. И теперь нам нужно его узнать.
Выводим список контейнеров:
docker ps --all
	Параметр ‘--all’ требует показать все контейнеры;
	если --all не указан, то будут показаны только запущенные контейнеры.
	Это в принципе нас устраивает, но как же новые знания?
В колонке NAMES видим искомое - “clever_austin”. Теперь попробуем присоединиться к нему:
docker attach clever_austin
Отлично, консоль снова “висит”, отцепляемся.
Теперь неплохо бы изменить имя контейнера: 
docker rename clever_austin portainer
А также приучить его сразу запускаться в фоне:
…

Меняем порт с 9001 на 9000
...

Запуск после перезагрузки:
docker update --restart=always portainer


просмотр результата: 10.230.10.125:9000
...

Все работает, можно удалять:
docker rm portainer

Зачем удалять? Чтобы сделать все с начала и как положено:
docker run --name portainer --restart always -v portainer:/data -v /var/run/docker.sock:/var/run/docker.sock -p 9000:9000 -d portainer/portainer

Итог:
docker  volume create --name portainer
docker run --name portainer --restart always -v portainer:/data -v /var/run/docker.sock:/var/run/docker.sock -p 9000:9000 -d portainer/portainer


Хранение данных
Теперь настало время разобраться с двумя вопросам: как в докере устроено хранение “полезных” данных, и где эти данные лучше размещать.

//TODO: как хранятся данные и зачем нужны дата-контейнеры

//TODO: где храним данные:
1. Храним данные у себя на машине: бОльшие накладные расходы при работе через коммутатор, привязанный к физической сети - подходит только при использовании быстрых сетей типа 10gbe или виртуального коммутатора внутренней сети.
wget http://distro.ibiblio.org/tinycorelinux/5.x/x86/tcz/cifs-utils.tcz
tce-load -i cifs-utils.tcz
sudo mkdir /mnt/datashare
sudo mount -t cifs //yourhost/sharedfolder /mnt/datashare -o user=usr,password=pwd

Оптимальный вариант для нас - хранение в докер-машине, причем по стандартным путям. 
Для удобства доступа из windows можно расшарить, или ходить через winscp

Развертывание приложений

Итак, ставим postgres и gogs.

Создаем дата-контейнер:
docker volume create --name=pgdata
Контейнер будет размещен в /var/lib/docker/volumes/pgdata.
Можно расположить в другом месте, например в /data:
docker volume create --opt device=/data --name=pgdata

Запускаем postgres:
docker run --name postgres95 -p 5432:5432 -v pgdata:/var/lib/postgresql/data -e POSTGRES_USER=postgres -e POSTGRES_PASSWORD=123 -d postgres:9
Что будет:
будет скачан образ postgres последней версии в линейке 9 (можно указать "postgres:9.5.4" или просто "postgres" для получения самой свежей версии, подробнее здесь: https://hub.docker.com/_/postgres/)
Создан контейнер с именем "postgres95"
Порт 5432 будет доступен снаружи по порту, внезапно, 5432
Базы будут складываться в /var/lib/docker/volumes/pgdata (убедиться поможет winscp)
Установлены логин/пароль
Pg будет переведен в фоновый режим (detached, ключ -d)
//TODO: описать, откуда взялся путь “/var/lib/postgresql/data”, и где вообще брать примеры запуска для образов 
Кстати, если сейчас создать второй контейнер, к примеру postgres-for-tests, то он создастся практически мгновенно.

Самый простой способ проверить работу - поставить pgadmin и подключиться:
cinst pgadmin3
Работу с pgadmin опустим за несложностью (upd: уже вышел pgadmin 4).

Ставим gogs:
docker run --name=gogs -p 10022:22 -p 10080:3000 -v /data/gogs:/data -d gogs/gogs
Порт 22 будет проброшен наружу как 10022, а основной порт 3000 - как 10080
Данные будут лежать в /data/gogs. Можно, как и с postgres, сделать volume и прицепить его к gogs:
docker volume create --name=gogs
docker run --name=gogs -p 10022:22 -p 10080:3000 -v gogs:/data -d gogs/gogs

Теперь можно посмотреть на результат:
Узнаем адрес докер-машины:
docker-machine env
У меня DOCKER_HOST = "tcp://10.230.10.125:2376"
Идем по адресу
http://10.230.10.125:10080


//TODO: compose
//TODO: backup
//TODO: migration
//TODO: service discovery
Приложения
Что почитать

Docker Documentation
https://docs.docker.com/
Образы и контейнеры Docker в картинках
https://habrahabr.ru/post/272145/
Установка docker-machine
https://github.com/docker/machine/blob/master/README.md
https://docs.docker.com/machine/install-machine/
Хранение данных в docker
https://blog.amartynov.ru/docker-named-volumes/
Управление томами данных (дата-контейнерами)
https://docs.docker.com/engine/tutorials/dockervolumes/#/backup-restore-or-migrate-data-volumes
Статья на Хабре “Полное практическое руководство по Docker: с нуля до кластера на AWS”
https://habrahabr.ru/post/310460/
Статья в Хакере “Знакомимся с основными возможностями Docker”
https://xakep.ru/2015/06/01/docker-usage/
Погружаемся в Docker: Dockerfile и коммуникация между контейнерами
https://habrahabr.ru/company/infobox/blog/240623/



docker-machine: стандартный логин/пароль
Логин: docker
Пароль: tcuser
docker-machine: основные команды
docker-machine ls -a
Список всех машин на хосте. Активная (с которой сейчас “соединены”) отмечена звездочкой.
docker-machine start default
Запуск машины default
docker-machine stop default
Остановка машины
docker-machine ssh default ls
Выполнение команды ls на default (но так неудобно, см. "docker-machine: ssh")
docker-machine active
Имя активной машины. Активная - это к контексту которой мы сейчас подключены, и куда будут слаться команды тип docker run
docker-machine config
Конфигурация подключения к машине (сертификаты, адрес)
docker-machine env
Параметры текущей машины
docker-machine env default | iex
Установка машины default в качестве активной, то есть устанавливается текущее окружение. После этого можно приступать к созданию контейнеров.
docker-machine ip default
ip машины default
docker-machine --help



docker-machine: где хранятся профили docker-хостов
Это каталог %userprofile%\.docker\machine\machines\. Для каждого профиля создается отдельный каталог с именем docker-хоста, в нем создается файл config.json, остальные файлы вторичны. Удаление каталога равносильно удалению профиля docker-хоста. Сам docker-хост при этом, разумеется, продолжает существовать. Добавление же каталога с “правильным” config.json приводит к добавлению нового docker-хоста.
Кстати, отсюда практическая рекомендация: если на хосте работает не один пользователь

docker-machine: управление удаленным docker-хостом
Источник: https://docs.docker.com/v1.10/machine/drivers/generic

Предположим, есть удаленный docker-хост и хочется работать с ним через docker-machine со своего компьютера. Для этого используется команда create с помощью драйвера generic, примерно так:
docker-machine create --driver generic --generic-ip-address <Имя или ip докер-хоста> <Имя>
В моем случае, если я захочу подключить ранее созданный docker-хост с другого ПК, мне нужно будет написать:
docker-machine.exe -debug create --driver generic --generic-ip-address 10.230.10.125 remote-docker
В результате появится конфиг по адресу %userprofile%\.docker\machine\machines\remote-docker\config.json
Но при этом команда завершится ошибкой, так как у нас нет нужных сертификатов.
//TODO: откуда скопировать, куда прописать, или как работать без ssl

docker-machine: статический IP
Сунуть в конфиг:
echo "ifconfig eth1 192.168.99.100 netmask 255.255.255.0 broadcast 192.168.99.255 up" | docker-machine ssh default sudo tee /var/lib/boot2docker/bootsync.sh > /dev/null
docker-machine: перегенерация сертификатов
docker-machine regenerate-certs default 
docker-machine: пакетный менеджер (установка приложений)
В boot2docker используется пакетный менеджер tce-load, пришедший из tiny linux. Вообще виртуалка boot2docker, генерируемая с помощью docker-machine, по сути и есть tiny linux.
Пакетов достаточно много, посмотреть список можно здесь: http://distro.ibiblio.org/tinycorelinux/tcz_2x.html
 
Синтаксис:
tce-load <packagename>
 
Пример установки git:
tce-load git
linux: удаленный доступ по ssh
Варианты
docker-machine:
docker-machine ssh default ls
где default - имя docker-хоста, ls - команда
 
open-ssh:
cinst win32-openssh
ssh docker@10.230.10.125
 
putty:
cinst putty
putty docker@10.230.10.125
Или putty без параметров, тогда откроется окно настроек:

linux: операции с файлами через scp
Цели
Наладить передачу данных между docker-machine (DM) и хостом на windows
Иметь gui
Иметь возможность копипастить команды из линуксовых мануалов в powershell

Приложения
winscp - gui-приложение, типа total commander. Позволяет все делать мышкой, при необходимости есть консоль через gui. Можно создавать и редактировать файлы.
 
putty - терминальный клиент, умеющий ssh. В составе есть cli-утилита pscp, позволяющая копипастить команды из linux-мануалов, заменяя scp на pscp.
 
open-ssh: набор cli-утилит - ssh, scp и т.д. В последних версиях scp пропал, возможно по ошибке, рассматривать не будем. Все команды можно копипастить из мануалов один в один. Установка: "cinst win32-openssh". (upd: пакет был пойман на тапке диверсии в виде отказа docker-machine признавать собственные сертификаты, поэтому информация о нем оставлена с целью обхода граблей)
 
Использование
winscp
Установка:
cinst winscp
Подключение:
Запускаем, вводим имя DM, логин/пароль, жмем "Еще":

Здесь настроим выполнение команд под полными правами: выбираем пункт "SCP/оболочка", значение "Командная оболочка" ставим "sudo su -".

Жмем “ОК”, “Войти", можно работать:

В нижней строке можно выполнять консольные команды.
 
Putty
Установка:
cinst putty
Копирование "c:\temp\file.txt" с хоста на docker-хост в папку "/data":
pscp c:\temp\file.txt docker@10.230.10.125:/data
Копирование с docker-хоста "/data/file.txt" в "c:\temp\":
pscp docker@10.230.10.125:/data/file.txt c:\temp\file.txt

docker-machine create: certificate signed by unknown authority
Если найдется добрый человек, который объяснит причину столь дивного поведения и, что важнее, причину столь странных последствий, буду очень признателен. 
Так вот, если при создании docker-хоста на этапе подключения по ssh получаем указанное сообщение, то причина, скорее всего, проста - в системе установлен ssh-клиент, и docker-machine пытается его использовать. Для диагностики выполняем команду с ключом -debug:
docker-machine -debug create --driver hyperv --hyperv-virtual-switch local default
Если в выводе есть информация об использовании стороннего ssh-клиента, то придется его найти и убить. Либо решать вопрос с кошерностью сертификатов.
Подключение без SSL
Защищенное соединение - это прекрасно, но иногда мешает. Docker по умолчанию слушает порт 2376 для защищенных соединений, и порт 2375 для незащищенных.
В случае boot2docker по умолчанию слушается только порт 2376 и принимаются только защищенные соединения (напомню, boot2docker - это виртуальная машина с docker-хостом, которую создает docker-machine).
Чтобы не погружаться в дебри, достаточно поднять прокси-контейнер, обслуживающий порт 2375 без sms и регистрации tls:
docker run -d -p 2375:2375 --restart always --volume=/var/run/docker.sock:/var/run/docker.sock --name=docker-http sequenceiq/socat
Поиск неиспользуемых томов
docker volume ls -f dangling=true
docker volume rm $(docker volume ls -q -f dangling=true)
Пример: поднятие zabbix
Источник: https://hub.docker.com/r/monitoringartist/zabbix-xxl/

# создание дата-контейнера
docker run -d -v /var/lib/mysql --name zabbix-db-storage busybox:latest

# Поднятие БД, innodb_buffer_pool_size=1GB
docker run -d --name zabbix-db -v /backups:/backups -v /etc/localtime:/etc/localtime:ro --volumes-from zabbix-db-storage --env="MARIADB_USER=zabbix" --env="MARIADB_PASS=my_password" monitoringartist/zabbix-db-mariadb

# Поднятие zabbix
docker run -d --name zabbix -p 80:80 -p 10051:10051 -v /etc/localtime:/etc/localtime:ro --link zabbix-db:zabbix.db --env="ZS_DBHost=zabbix.db" --env="ZS_DBUser=zabbix" --env="ZS_DBPassword=my_password" monitoringartist/zabbix-xxl:latest

# Минута ожидания...
# Web-интерфейс Zabbix доступен через порт 80, порт сервера (куда стучатся агенты) -10051

Пример: создание бэкапа и восстановление

# Создание бэкапа конфигурации, без накопленных данных
docker exec -ti zabbix-db /zabbix-backup/zabbix-mariadb-dump -u zabbix -p my_password -o /backups

# Полный бэкап базы
docker exec -ti zabbix-db bash -c "mysqldump -u zabbix -pmy_password zabbix | bzip2 -cq9 > /backups/zabbix_db_dump_$(date +%Y-%m-%d-%H.%M.%S).sql.bz2"

# Удаление контейнера zabbix
docker rm -f zabbix

# Восстановление базы из бэкапа
docker exec -i zabbix-db sh -c 'bunzip2 -dc /backups/zabbix_db_dump_2016-05-25-02.57.46.sql.bz2 | mysql -uzabbix -p --password=my_password zabbix'

# Поднятие zabbix
docker run -d --name zabbix -p 80:80 -p 10051:10051 -v /etc/localtime:/etc/localtime:ro --link zabbix-db:zabbix.db --env="ZS_DBHost=zabbix.db" --env="ZS_DBUser=zabbix" --env="ZS_DBPassword=my_password" monitoringartist/zabbix-xxl:latest


